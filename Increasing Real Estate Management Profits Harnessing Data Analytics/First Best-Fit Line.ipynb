{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Best-Fit Line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(60000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 60 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import count_nonzero\n",
    "from numpy import median\n",
    "from numpy import mean\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import random\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "#import os\n",
    "#import zipfile\n",
    "import scipy.stats\n",
    "from collections import Counter\n",
    "\n",
    "# import pandas_profiling\n",
    "# from pandas_profiling import ProfileReport\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, ElasticNet, Lasso, Ridge\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import accuracy_score, auc, classification_report, confusion_matrix, f1_score\n",
    "from sklearn.metrics import plot_confusion_matrix, plot_roc_curve\n",
    "\n",
    "%matplotlib inline\n",
    "#sets the default autosave frequency in seconds\n",
    "%autosave 60 \n",
    "sns.set_style('dark')\n",
    "sns.set(font_scale=1.2)\n",
    "\n",
    "plt.rc('axes', titlesize=9)\n",
    "plt.rc('axes', labelsize=14)\n",
    "plt.rc('xtick', labelsize=12)\n",
    "plt.rc('ytick', labelsize=12)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Webscraping\n",
    "#import requests\n",
    "#from bs4 import BeautifulSoup\n",
    "\n",
    "# Use Folium library to plot values on a map.\n",
    "#import folium\n",
    "\n",
    "# Use Feature-Engine library\n",
    "#import feature_engine\n",
    "#import feature_engine.missing_data_imputers as mdi\n",
    "#from feature_engine.outlier_removers import Winsorizer\n",
    "#from feature_engine import categorical_encoders as ce\n",
    "#from feature_engine.discretisation import EqualWidthDiscretiser, EqualFrequencyDiscretiser, DecisionTreeDiscretiser\n",
    "#from feature_engine.encoding import OrdinalEncoder\n",
    "\n",
    "pd.set_option('display.max_columns',None)\n",
    "#pd.set_option('display.max_rows',None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.float_format','{:.2f}'.format)\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"rentaldate.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"propertyinfo.csv\")\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.merge(left=df, right=df2, on=\"st_property_id\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df3.to_csv(\"merge1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.read_csv(\"watershed.csv\")\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.read_csv(\"propertytype.csv\")\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = pd.merge(left=df4, right=df5, on=\"property_type_id\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df6.to_csv(\"merge2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = pd.read_csv(\"rentalprice.csv\")\n",
    "df7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7.drop(['location'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df9 = pd.merge(left=df6, right=df7, on=\"property_type_id\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df9.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df9.to_csv(\"merge3.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ws_property_id</th>\n",
       "      <th>location</th>\n",
       "      <th>property_type_id</th>\n",
       "      <th>current_monthly_rent</th>\n",
       "      <th>apt_house</th>\n",
       "      <th>num_bedrooms</th>\n",
       "      <th>kitchen</th>\n",
       "      <th>shared</th>\n",
       "      <th>percentile_10th_price</th>\n",
       "      <th>percentile_90th_price</th>\n",
       "      <th>sample_nightly_rent_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W1</td>\n",
       "      <td>L9531</td>\n",
       "      <td>R6</td>\n",
       "      <td>1060</td>\n",
       "      <td>apartment</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>168</td>\n",
       "      <td>392</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W1</td>\n",
       "      <td>L9531</td>\n",
       "      <td>R6</td>\n",
       "      <td>1060</td>\n",
       "      <td>apartment</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>154</td>\n",
       "      <td>286</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W1</td>\n",
       "      <td>L9531</td>\n",
       "      <td>R6</td>\n",
       "      <td>1060</td>\n",
       "      <td>apartment</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>192</td>\n",
       "      <td>357</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>W1</td>\n",
       "      <td>L9531</td>\n",
       "      <td>R6</td>\n",
       "      <td>1060</td>\n",
       "      <td>apartment</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>94</td>\n",
       "      <td>531</td>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>W1</td>\n",
       "      <td>L9531</td>\n",
       "      <td>R6</td>\n",
       "      <td>1060</td>\n",
       "      <td>apartment</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>154</td>\n",
       "      <td>480</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14883</th>\n",
       "      <td>W99</td>\n",
       "      <td>L1944</td>\n",
       "      <td>R14</td>\n",
       "      <td>6000</td>\n",
       "      <td>house</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>192</td>\n",
       "      <td>829</td>\n",
       "      <td>575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14884</th>\n",
       "      <td>W99</td>\n",
       "      <td>L1944</td>\n",
       "      <td>R14</td>\n",
       "      <td>6000</td>\n",
       "      <td>house</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>97</td>\n",
       "      <td>240</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14885</th>\n",
       "      <td>W99</td>\n",
       "      <td>L1944</td>\n",
       "      <td>R14</td>\n",
       "      <td>6000</td>\n",
       "      <td>house</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>136</td>\n",
       "      <td>335</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14886</th>\n",
       "      <td>W99</td>\n",
       "      <td>L1944</td>\n",
       "      <td>R14</td>\n",
       "      <td>6000</td>\n",
       "      <td>house</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>136</td>\n",
       "      <td>336</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14887</th>\n",
       "      <td>W99</td>\n",
       "      <td>L1944</td>\n",
       "      <td>R14</td>\n",
       "      <td>6000</td>\n",
       "      <td>house</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>111</td>\n",
       "      <td>276</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14888 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ws_property_id location property_type_id  current_monthly_rent  apt_house  num_bedrooms kitchen shared  percentile_10th_price  percentile_90th_price  sample_nightly_rent_price\n",
       "0                 W1    L9531               R6                  1060  apartment             2       Y      N                    168                    392                        322\n",
       "1                 W1    L9531               R6                  1060  apartment             2       Y      N                    154                    286                        230\n",
       "2                 W1    L9531               R6                  1060  apartment             2       Y      N                    192                    357                        266\n",
       "3                 W1    L9531               R6                  1060  apartment             2       Y      N                     94                    531                        427\n",
       "4                 W1    L9531               R6                  1060  apartment             2       Y      N                    154                    480                        154\n",
       "...              ...      ...              ...                   ...        ...           ...     ...    ...                    ...                    ...                        ...\n",
       "14883            W99    L1944              R14                  6000      house             2       Y      N                    192                    829                        575\n",
       "14884            W99    L1944              R14                  6000      house             2       Y      N                     97                    240                        199\n",
       "14885            W99    L1944              R14                  6000      house             2       Y      N                    136                    335                        188\n",
       "14886            W99    L1944              R14                  6000      house             2       Y      N                    136                    336                        186\n",
       "14887            W99    L1944              R14                  6000      house             2       Y      N                    111                    276                        169\n",
       "\n",
       "[14888 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"merge3.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression (StatsModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ws_property_id', 'location', 'property_type_id', 'current_monthly_rent', 'apt_house', 'num_bedrooms', 'kitchen', 'shared', 'percentile_10th_price', 'percentile_90th_price', 'sample_nightly_rent_price'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[['sample_nightly_rent_price']]\n",
    "X = df[['current_monthly_rent','num_bedrooms','percentile_10th_price', 'percentile_90th_price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(y,X).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>sample_nightly_rent_price</td> <th>  R-squared:         </th> <td>   0.838</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                       <td>OLS</td>            <th>  Adj. R-squared:    </th> <td>   0.838</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>Least Squares</td>       <th>  F-statistic:       </th> <td>1.927e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>                 <td>Thu, 09 Dec 2021</td>      <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                     <td>12:08:27</td>          <th>  Log-Likelihood:    </th> <td> -85816.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>          <td> 14888</td>           <th>  AIC:               </th> <td>1.716e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>              <td> 14883</td>           <th>  BIC:               </th> <td>1.717e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>                  <td>     4</td>           <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>          <td>nonrobust</td>         <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>               <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                 <td>   15.0587</td> <td>    2.257</td> <td>    6.673</td> <td> 0.000</td> <td>   10.636</td> <td>   19.482</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>current_monthly_rent</th>  <td>    0.0004</td> <td>    0.001</td> <td>    0.749</td> <td> 0.454</td> <td>   -0.001</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_bedrooms</th>          <td>   -1.3017</td> <td>    1.379</td> <td>   -0.944</td> <td> 0.345</td> <td>   -4.005</td> <td>    1.401</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>percentile_10th_price</th> <td>    0.5275</td> <td>    0.010</td> <td>   50.610</td> <td> 0.000</td> <td>    0.507</td> <td>    0.548</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>percentile_90th_price</th> <td>    0.4589</td> <td>    0.003</td> <td>  175.019</td> <td> 0.000</td> <td>    0.454</td> <td>    0.464</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1054.485</td> <th>  Durbin-Watson:     </th> <td>   2.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5088.129</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-0.147</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 5.849</td>  <th>  Cond. No.          </th> <td>9.43e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 9.43e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                OLS Regression Results                               \n",
       "=====================================================================================\n",
       "Dep. Variable:     sample_nightly_rent_price   R-squared:                       0.838\n",
       "Model:                                   OLS   Adj. R-squared:                  0.838\n",
       "Method:                        Least Squares   F-statistic:                 1.927e+04\n",
       "Date:                       Thu, 09 Dec 2021   Prob (F-statistic):               0.00\n",
       "Time:                               12:08:27   Log-Likelihood:                -85816.\n",
       "No. Observations:                      14888   AIC:                         1.716e+05\n",
       "Df Residuals:                          14883   BIC:                         1.717e+05\n",
       "Df Model:                                  4                                         \n",
       "Covariance Type:                   nonrobust                                         \n",
       "=========================================================================================\n",
       "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------\n",
       "const                    15.0587      2.257      6.673      0.000      10.636      19.482\n",
       "current_monthly_rent      0.0004      0.001      0.749      0.454      -0.001       0.001\n",
       "num_bedrooms             -1.3017      1.379     -0.944      0.345      -4.005       1.401\n",
       "percentile_10th_price     0.5275      0.010     50.610      0.000       0.507       0.548\n",
       "percentile_90th_price     0.4589      0.003    175.019      0.000       0.454       0.464\n",
       "==============================================================================\n",
       "Omnibus:                     1054.485   Durbin-Watson:                   2.100\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5088.129\n",
       "Skew:                          -0.147   Prob(JB):                         0.00\n",
       "Kurtosis:                       5.849   Cond. No.                     9.43e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 9.43e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       281.38\n",
       "1       225.36\n",
       "2       277.98\n",
       "3       306.13\n",
       "4       314.38\n",
       "         ...  \n",
       "14883   496.57\n",
       "14884   176.19\n",
       "14885   240.35\n",
       "14886   240.81\n",
       "14887   200.09\n",
       "Length: 14888, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = smf.ols(formula='Lottery ~ Literacy + Wealth + Region', data=df).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "fig = sm.graphics.plot_regress_exog(model, 'x_variables', fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(bins=50, figsize=(20,10))\n",
    "plt.suptitle('Histogram Feature Distribution', x=0.5, y=1.02, ha='center', fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot(figsize=(20,10))\n",
    "plt.suptitle('BoxPlots Feature Distribution', x=0.5, y=1.02, ha='center', fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 4 rows and 1 column (can be expanded)\n",
    "\n",
    "fig, ax = plt.subplots(4,1, sharex=False, figsize=(16,16))\n",
    "fig.suptitle('Main Title')\n",
    "\n",
    "\n",
    "sns.barplot(x=\"\", y=\"\", data=df, ax=ax[0])\n",
    "ax[0].set_title('Title of the first chart')\n",
    "#ax[0].tick_params('x', labelrotation=45)\n",
    "\n",
    "sns.barplot(x=\"\", y=\"\", data=df, ax=ax[1])\n",
    "ax[1].set_title('Title of the second chart')\n",
    "#ax[1].tick_params('x', labelrotation=45)\n",
    "\n",
    "sns.barplot(x=\"\", y=\"\", data=df, ax=ax[2])\n",
    "ax[2].set_title('Title of the third chart')\n",
    "#ax[2].tick_params('x', labelrotation=45)\n",
    "\n",
    "sns.barplot(x=\"\", y=\"\", data=df, ax=ax[3])\n",
    "ax[3].set_title('Title of the fourth chart')\n",
    "#ax[3].tick_params('x', labelrotation=45)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 1 rows and 2 columns (can be expanded)\n",
    "\n",
    "fig, ax = plt.subplots(1,2, sharex=False, figsize=(16,5))\n",
    "fig.suptitle('Main Title')\n",
    "\n",
    "sns.countplot(x=\"\", data=df, hue=, ax=ax[0])\n",
    "ax[0].set_title('Title of the first chart')\n",
    "ax[0].tick_params('x', labelrotation=45)\n",
    "\n",
    "sns.countplot(x=\"\", data=df, hue=, ax=ax[1])\n",
    "ax[1].set_title('Title of the second chart')\n",
    "ax[1].tick_params('x', labelrotation=45)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot 2 by 2 subplots\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2, sharex=False, figsize=(20,20))\n",
    "fig.suptitle('Main Title', y=0.5)\n",
    "\n",
    "sns.countplot(x=\"\", data=df, ax=ax1)\n",
    "ax1.set_title('Title of the first chart', size=20)\n",
    "#ax1.tick_params('x', labelrotation=45)\n",
    "\n",
    "\n",
    "sns.countplot(x=\"\", data=df, ax=ax2)\n",
    "ax2.set_title('Title of the second chart', size=20)\n",
    "#ax2.tick_params('x', labelrotation=45)\n",
    "\n",
    "sns.countplot(x=\"\", data=df, ax=ax3)\n",
    "ax3.set_title('Title of the third chart', size=20)\n",
    "#ax3.tick_params('x', labelrotation=45)\n",
    "\n",
    "\n",
    "sns.countplot(x=\"\", data=df, ax=ax4)\n",
    "ax4.set_title('Title of the fourth chart', size=20)\n",
    "#ax4.tick_params('x', labelrotation=45)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,40))\n",
    "\n",
    "plt.subplot(7,2,1)\n",
    "plt.title(\"\", size=20)\n",
    "sns.countplot()\n",
    "\n",
    "plt.subplot(7,2,2)\n",
    "plt.title(\"\", size=20)\n",
    "sns.countplot()\n",
    "\n",
    "plt.subplot(7,2,3)\n",
    "plt.title(\"\", size=20)\n",
    "sns.countplot()\n",
    "\n",
    "plt.subplot(7,2,4)\n",
    "plt.title(\"\", size=20)\n",
    "sns.countplot()\n",
    "\n",
    "plt.subplot(7,2,5)\n",
    "plt.title(\"\", size=20)\n",
    "sns.barplot()\n",
    "\n",
    "plt.subplot(7,2,6)\n",
    "plt.title(\"\", size=20)\n",
    "sns.barplot()\n",
    "\n",
    "plt.subplot(7,2,7)\n",
    "plt.title(\"\", size=20)\n",
    "sns.barplot()\n",
    "\n",
    "plt.subplot(7,2,8)\n",
    "plt.title(\"\", size=20)\n",
    "sns.barplot()\n",
    "\n",
    "plt.subplot(7,2,9)\n",
    "plt.title(\"\", size=20)\n",
    "sns.scatterplot()\n",
    "\n",
    "plt.subplot(7,2,10)\n",
    "plt.title(\"\", size=20)\n",
    "sns.scatterplot()\n",
    "\n",
    "plt.subplot(7,2,11)\n",
    "plt.title(\"\", size=20)\n",
    "sns.scatterplot()\n",
    "\n",
    "plt.subplot(7,2,12)\n",
    "plt.title(\"\", size=20)\n",
    "sns.scatterplot()\n",
    "\n",
    "plt.subplot(7,2,13)\n",
    "plt.title(\"\", size=20)\n",
    "sns.relplot()\n",
    "\n",
    "plt.subplot(7,2,14)\n",
    "plt.title(\"\", size=20)\n",
    "sns.relplot()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "\n",
    "g = sns.catplot(x='', hue = '', row = '',\n",
    "            kind='count', data=ratings_df,\n",
    "            height = 3, aspect = 1)\n",
    "\n",
    "g.set_xlabels(\"\")\n",
    "g.set_ylabels(\"\")\n",
    "#g = (g.set_axis_labels(\"Tip\",\"Total bill(USD)\").set(xlim=(0,10),ylim=(0,100)\n",
    "\n",
    "\n",
    "g.set(xlim=(0,None))\n",
    "g.set_xticklabels(rotation=90)\n",
    "\n",
    "plt.suptitle('', x=0.5, y=1.02, ha='center', fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "sns.catplot(x=\"calories\", y=\"restaurant\",\n",
    "\n",
    "                hue=\"is_salad\", ci=None,\n",
    "\n",
    "                data=df_calories, color=None, linewidth=3, showfliers = False,\n",
    "\n",
    "                orient=\"h\", height=20, aspect=1, palette=None,\n",
    "\n",
    "                kind=\"box\", dodge=True)\n",
    "\n",
    "plt.xlabel(\"\", size=20)\n",
    "plt.ylabel(\"\", size=20)\n",
    "plt.suptitle('', x=0.5, y=1.02, ha='center', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "sns.relplot(x=\"age\", y=\"eval\", hue=\"gender\",\n",
    "            row=\"tenure\",\n",
    "            data=ratings_df, height = 3, aspect = 2)\n",
    "\n",
    "plt.xlabel(\"\", size=20)\n",
    "plt.ylabel(\"\", size=20)\n",
    "plt.suptitle('', x=0.5, y=1.02, ha='center', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = df[['date','extraction','month', 'day']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(30,10))\n",
    "sns.lineplot(x=df.date,y=df.amount,data=df, estimator=None)\n",
    "plt.title(\"\", fontsize=20)\n",
    "plt.xlabel(\"\", fontsize=20)\n",
    "plt.ylabel(\"\", fontsize=20)\n",
    "plt.legend(['',''])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(30,10))\n",
    "sns.lineplot(x=df.month,y=df.amount,data=df, estimator=None)\n",
    "plt.title(\"\", fontsize=20)\n",
    "plt.xlabel(\"\", fontsize=20)\n",
    "plt.ylabel(\"\", fontsize=20)\n",
    "plt.legend(['',''])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(30,10))\n",
    "sns.lineplot(x=df.month,y=df.amount,data=df, estimator=None)\n",
    "plt.title(\"\", fontsize=20)\n",
    "plt.xlabel(\"\", fontsize=20)\n",
    "plt.ylabel(\"\", fontsize=20)\n",
    "plt.legend(['',''])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "plt.suptitle('Pairplots of features', x=0.5, y=1.02, ha='center', fontsize=20)\n",
    "sns.pairplot(df.sample(500))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x='', y='',data=df, kind='scatter')\n",
    "\n",
    "sns.jointplot(x='', y='',data=df, kind='scatter')\n",
    "\n",
    "sns.jointplot(x='', y='',data=df, kind='scatter')\n",
    "\n",
    "sns.jointplot(x='', y='',data=df, kind='scatter')\n",
    "\n",
    "sns.jointplot(x='', y='',data=df, kind='kde')\n",
    "\n",
    "sns.jointplot(x='', y='',data=df, kind='kde')\n",
    "\n",
    "sns.jointplot(x='', y='',data=df, kind='hex')\n",
    "\n",
    "sns.jointplot(x='', y='',data=df, kind='hex')\n",
    "\n",
    "sns.jointplot(x='', y='',data=df, kind='reg',scatter_kws={'color':'k'},line_kws={'color':'red'})\n",
    "\n",
    "sns.jointplot(x='', y='',data=df, kind='reg',scatter_kws={'color':'k'},line_kws={'color':'red'})\n",
    "\n",
    "sns.lmplot(x='num_items', y='total_value', data=df, scatter_kws={'s': 1, 'alpha': 0.1}, height=5, aspect=1,\n",
    "           line_kws={'lw': 2, 'color': 'red'})\n",
    "\n",
    "sns.lmplot(x='num_items', y='total_value', data=df, scatter_kws={'s': 1, 'alpha': 0.1}, height=5, aspect=1,\n",
    "           line_kws={'lw': 2, 'color': 'red'})\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_color = {'color': 'red'}\n",
    "fig , ax = plt.subplots(2,2, figsize=(20,20))\n",
    "\n",
    "#Feature\n",
    "\n",
    "ax1 = sns.regplot(x=X_test.bmi, y=lr_pred, line_kws=line_color, ax=ax[0,0])\n",
    "ax1.set_xlabel(\"x\")\n",
    "ax1.set_ylabel(\"y\")\n",
    "ax1.set_title(\"Plot 1\", size=15)\n",
    "\n",
    "#Feature\n",
    "\n",
    "ax2 = sns.regplot(x=X_test.s5, y=lr_pred, line_kws=line_color, ax=ax[0,1])\n",
    "ax2.set_xlabel(\"x\")\n",
    "ax2.set_ylabel(\"y\")\n",
    "ax2.set_title(\"Plot 2\", size=15)\n",
    "\n",
    "#Feature\n",
    "\n",
    "ax3 = sns.regplot(x=X_test.bp, y=lr_pred, line_kws=line_color, ax=ax[1,0])\n",
    "ax3.set_xlabel(\"x\")\n",
    "ax3.set_ylabel(\"y\")\n",
    "ax3.set_title(\"Plot 3\", size=15)\n",
    "\n",
    "#Feature\n",
    "\n",
    "ax4 = sns.regplot(x=X_test.s4, y=lr_pred, line_kws=line_color, ax=ax[1,1])\n",
    "ax4.set_xlabel(\"x\")\n",
    "ax4.set_ylabel(\"y\")\n",
    "ax1.set_title(\"Plot 4\", size=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FacetGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(data=df, col=\"column_name\", height=3, aspect=1)\n",
    "g.map(plt.scatter, \"numeric\", \"numeric\")\n",
    "g.add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geospatial Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = usa_stores[['City','Latitude','Longtitude','Sentiment','Revenue']]\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map(location=[37.090240,-95.712891], zoom_start=5)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_df = pd.DataFrame(mapping.groupby([\"City\",\"Latitude\",\"Longtitude\"]).mean())\n",
    "map_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folium.Marker(location=[33.76,-84.42], popup=\"Atlanta\", tooltip=\"Sentiment=83.69, Revenue=292.57\").add_to(m)\n",
    "folium.Marker(location=[36.23,-115.27], popup=\"Las Vegas\", tooltip=\"Sentiment=83.72, Revenue=187.40\").add_to(m)\n",
    "folium.Marker(location=[34.11,-118.41], popup=\"Los Angeles\", tooltip=\"Sentiment=83.75, Revenue=255.95\").add_to(m)\n",
    "folium.Marker(location=[40.69,-73.92], popup=\"New York\", tooltip=\"Sentiment=83.71, Revenue=328.38\").add_to(m)\n",
    "folium.Marker(location=[32.83,-117.12], popup=\"San Diego\", tooltip=\"Sentiment=83.70, Revenue=272.93\").add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.save(\"filename.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_geo = f\"malaysia.geojson\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map2 = folium.Map(location=[4.210484,108.975766], zoom_start=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now to create a `Choropleth` map, we will use the *choropleth* method with the following main parameters:\n",
    "\n",
    "1.  `geo_data`, which is the GeoJSON file.\n",
    "2.  `data`, which is the dataframe containing the data.\n",
    "3.  `columns`, which represents the columns in the dataframe that will be used to create the `Choropleth` map.\n",
    "4.  `key_on`, which is the key or variable in the GeoJSON file that contains the name of the variable of interest. To determine that, you will need to open the GeoJSON file using any text editor and note the name of the key or variable that contains the name of the countries, since the countries are our variable of interest. In this case, **name** is the key in the GeoJSON file that contains the name of the countries. Note that this key is case_sensitive, so you need to pass exactly as it exists in the GeoJSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folium.Choropleth(geo_data=state_geo, name=\"choropleth\").add_to(map2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()[\"target\"].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,9))\n",
    "sns.heatmap(df.corr(),cmap=\"coolwarm\",annot=True,fmt='.2f',linewidths=2)\n",
    "plt.title(\"\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of hypothesis testing is to answer the question, “Given a sample and an apparent effect, what is the probability of seeing such an effect by chance?” The first step is to quantify the size of the apparent effect by choosing a test statistic (t-test, ANOVA, etc). The next step is to define a null hypothesis, which is a model of the system based on the assumption that the apparent effect is not real. Then compute the p-value, which is the probability of the null hypothesis being true, and finally interpret the result of the p-value, if the value is low, the effect is said to be statistically significant, which means that the null hypothesis may not be accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T-Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the t-test for independent samples. For the independent t-test, the following assumptions must be met.\n",
    "\n",
    "-   One independent, categorical variable with two levels or group\n",
    "-   One dependent continuous variable\n",
    "-   Independence of the observations. Each subject should belong to only one group. There is no relationship between the observations in each group.\n",
    "-   The dependent variable must follow a normal distribution\n",
    "-   Assumption of homogeneity of variance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State the hypothesis\n",
    "\n",
    "-   $H_0: µ\\_1 = µ\\_2$ (\"there is no difference in evaluation scores between male and females\")\n",
    "-   $H_1: µ\\_1 ≠ µ\\_2$ (\"there is a difference in evaluation scores between male and females\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Levene's Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.levene(ratings_df[ratings_df['gender'] == 'female']['eval'],\n",
    "                   ratings_df[ratings_df['gender'] == 'male']['eval'], center='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Sample T-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, p = scipy.stats.ttest_1samp(a=df.dose, popmean=1.166667)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"T-test value is: \", t)\n",
    "print(\"p-value value is: \", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Samples T-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, p = scipy.stats.ttest_ind(a=df.len,b=df.dose, equal_var = True/False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"T-test value is: \",t)\n",
    "print(\"p-value value is: \",p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we group the data into cateries as the one-way ANOVA can't work with continuous variable - using the example from the video, we will create a new column for this newly assigned group our categories will be teachers that are:\n",
    "\n",
    "-   40 years and younger\n",
    "-   between 40 and 57 years\n",
    "-   57 years and older\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State the hypothesis\n",
    "\n",
    "-   $H_0: µ\\_1 = µ\\_2 = µ\\_3$ (the three population means are equal)\n",
    "-   $H_1:$ At least one of the means differ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Way ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = ols('len~supp', data=df).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aov_table = sm.stats.anova_lm(mod,typ=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aov_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_statistic, p_value = scipy.stats.f_oneway(forty_lower, forty_fiftyseven, fiftyseven_older)\n",
    "print(\"F_Statistic: {0}, P-Value: {1}\".format(f_statistic,p_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two-way ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod1 = ols('len~supp+dose', data=df).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aov1 = sm.stats.anova_lm(mod1,typ=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aov1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-square"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State the hypothesis:\n",
    "\n",
    "-   $H_0:$ The proportion of teachers who are tenured is independent of gender\n",
    "-   $H_1:$ The proportion of teachers who are tenured is associated with gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Cross-tab table\n",
    "\n",
    "cont_table  = pd.crosstab(ratings_df['tenure'], ratings_df['gender'])\n",
    "cont_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.chi2_contingency(cont_table, correction = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_square = scipy.stats.chi2_contingency(cont_table, correction = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Chi score is\", chi_square[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"P-value is\", chi_square[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Degrees of freedom is\", chi_square[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State the hypothesis:\n",
    "\n",
    "-   $H_0:$ Teaching evaluation score is not correlated with beauty score\n",
    "-   $H_1:$ Teaching evaluation score is correlated with beauty score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_correlation = scipy.stats.pearsonr(ratings_df['beauty'], ratings_df['eval'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pearson's correlation coefficient is\", pearson_correlation[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"P-value is\", pearson_correlation[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equal Width Discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"demoscorecat\"] = df[\"polityscore\"] #Make a copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = EqualWidthDiscretiser(bins=4, variables=['demoscorecat'], return_object=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc.binner_dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = disc.fit_transform(df)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"demoscorecat\"].value_counts().plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equal Frequency Discretizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"co2cat\"] = df2[\"co2emissions\"] #Make a copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = EqualFrequencyDiscretiser(q=5, variables=['co2cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc.fit(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc.binner_dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = disc.transform(df2)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[\"co2cat\"].value_counts().plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretisation + OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Choose which columns to be discretized first\n",
    "df3[\"incomecat\"] = df3[\"incomeperperson\"] #Make a copy\n",
    "df3[\"alccat\"] = df3[\"alcconsumption\"] #Make a copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to encode variables we need them returned as objects for feature-engine\n",
    "disc = EqualFrequencyDiscretiser(q=5, variables=['incomecat','alccat'], return_object=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = disc.fit_transform(df3)\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4[\"incomecat\"].value_counts().plot.bar()\n",
    "df4[\"alccat\"].value_counts().plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set y = target variable, and x = independant variables (both must be objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df4[['demoscorecat','incomecat', 'alccat']]\n",
    "df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.groupby('incomecat')['demoscorecat'].mean().plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.groupby('alccat')['demoscorecat'].mean().plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OrdinalEncoder(encoding_method = 'ordered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df5[['incomecat', 'alccat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df5['demoscorecat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transform = enc.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc.encoder_dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transform  # Transformed for monotonic relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([X_transform, y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([X_transform, y], axis=1).groupby('incomecat')['demoscorecat'].mean().plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretisation with Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['electricat'] = df4['relectricperperson'] #Make a copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let y = demoscorecat, and x = electricat, breastcancerper100th\n",
    "\n",
    "df6 = df4[['breastcancerper100th','electricat','demoscorecat']]\n",
    "df6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df6[['breastcancerper100th','electricat']]\n",
    "y = df6['demoscorecat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the decision tree discretiser indicating:\n",
    "# cross-validation number (cv)\n",
    "# how to evaluate model performance (scoring)\n",
    "# the variables we want to discretise (variables)\n",
    "# whether it is a target for regression or classification\n",
    "# and the grid with the parameters we want to test\n",
    "\n",
    "treeDisc = DecisionTreeDiscretiser(cv=5, scoring='accuracy', variables=['electricat'], regression=False,\n",
    "                                  param_grid={'max_depth':[1,2,3], 'min_samples_leaf':[2,4,6]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treeDisc.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treeDisc.binner_dict_['electricat'].best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treeDisc.scores_dict_['electricat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transform = treeDisc.transform(X) #Only electricat column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transform.electricat.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monotonic relationship with target: train set\n",
    "\n",
    "pd.concat([X_transform, y],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop unwanted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treat Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[''] = df[''].replace(np.nan,df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputer = mdi.MeanMedianImputer(imputation_method='median',variables=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputer.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = imputer.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rounding Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###pandas.DataFrame.round\n",
    "df[['internetuserate']] = df[['internetuserate']].round(decimals=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treat Duplicate Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated(keep='first').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.duplicated(keep=False)] #Check duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(ignore_index=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treat Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#windsorizer = Winsorizer(distribution='skewed',tail='both',fold=1.5, variables=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#windsorizer.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2 = windsorizer.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#windsorizer.left_tail_caps_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#windsorizer.right_tail_caps_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"breastcancerper100th\"] = df[\"breastcancerper100th\"].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"has_gas\"] = pd.get_dummies(data=df[\"has_gas\"],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"filename.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression (StatsModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['ExpirationMonth']\n",
    "X = df['NumStores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(y,X).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = smf.ols(formula='Lottery ~ Literacy + Wealth + Region', data=df).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "fig = sm.graphics.plot_regress_exog(model, 'x_variables', fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression (SKLearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression (StatsModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['']\n",
    "X = df['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.Logit(y, X).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logitfit = smf.logit(formula = 'DF ~ Debt_Service_Coverage + cash_security_to_curLiab + TNW', data = hgc).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logitfit = smf.logit(formula = 'DF ~ TNW + C(seg2)', data = hgcdev).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression (SKLearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:4]\n",
    "y = df.iloc[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.values, y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.2, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(y_train), Counter(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test,y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(estimator=lr, X=X_test, y_true=y_test, cmap='YlGnBu')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(estimator=lr, X=X_test, y=y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python code done by Dennis Lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
